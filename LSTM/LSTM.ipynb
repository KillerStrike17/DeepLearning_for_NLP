{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KillerStrike17/DeepLearning_for_NLP/blob/master/LSTM/LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf",
        "colab_type": "text"
      },
      "source": [
        "#Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ap77ruIqpC81",
        "colab_type": "code",
        "outputId": "02df1602-c15f-4ce5-c74e-6ee2f144852f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Feb  7 15:16:08 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.48.02    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P8    11W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA",
        "colab_type": "text"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JemNWp6tvGIg",
        "colab_type": "code",
        "outputId": "f802f88e-3306-4292-f41e-082e424b8373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        }
      },
      "source": [
        "!wget -O text.txt https://drive.google.com/u/0/uc?id=1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS&export=download"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-07 15:14:53--  https://drive.google.com/u/0/uc?id=1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS\n",
            "Resolving drive.google.com (drive.google.com)... 108.177.126.139, 108.177.126.100, 108.177.126.101, ...\n",
            "Connecting to drive.google.com (drive.google.com)|108.177.126.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-14-3o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/0elsrch4rfoehh4a1decjc7ue2igh137/1581087600000/02008525212197398114/*/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2020-02-07 15:14:58--  https://doc-14-3o-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/0elsrch4rfoehh4a1decjc7ue2igh137/1581087600000/02008525212197398114/*/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS\n",
            "Resolving doc-14-3o-docs.googleusercontent.com (doc-14-3o-docs.googleusercontent.com)... 108.177.119.132, 2a00:1450:4013:c00::84\n",
            "Connecting to doc-14-3o-docs.googleusercontent.com (doc-14-3o-docs.googleusercontent.com)|108.177.119.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10346 (10K) [text/plain]\n",
            "Saving to: ‘text.txt’\n",
            "\n",
            "text.txt            100%[===================>]  10.10K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-02-07 15:14:59 (85.9 MB/s) - ‘text.txt’ saved [10346/10346]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb",
        "colab_type": "text"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab_type": "code",
        "outputId": "d28cdd5c-ec06-4687-b954-9bb16c83a8a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "chars = list(set(data)) # List of Set of Unique characaters used in the text\n",
        "\n",
        "data_size, X_size = len(data), len(chars) \n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "\n",
        "#Forming a Dictionary of ID to Character and ViceVersa\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "# print(char_to_idx)\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}\n",
        "# print(idx_to_char)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY",
        "colab_type": "text"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb",
        "colab_type": "text"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "  return 1/(1+np.exp(-x))\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return y*(1-y)\n",
        "  \n",
        "def tanh(x): # tanh function\n",
        "  return ((np.exp(x) - np.exp(-x))/(np.exp(x)+np.exp(-x)))\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return 1-pow(y,2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE",
        "colab_type": "text"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Param Class to initialize name and parameter to different internal variables\n",
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212",
        "colab_type": "text"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V",
        "colab_type": "text"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size_a = Hidden_Layer_size #Number of Layers in one DNN\n",
        "size_b = z_size # Dimensionality of Hidden Layer\n",
        "size_c = X_size # Total Number of Character\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs",
        "colab_type": "text"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# All the operations in the functions are written based on the Equations\n",
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    # print(p.all())\n",
        "    \n",
        "  \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    # print(z)\n",
        "    f = sigmoid(np.add(np.dot(p.W_f.v,z),p.b_f.v))\n",
        "    # print(np.dot(p.W_f.v,z).shape)\n",
        "    # print(f.shape)\n",
        "    # print(p.b_f.v.shape)\n",
        "    # print(p.W_f.v.shape)\n",
        "    # print(z.shape)\n",
        "    \n",
        "    i = sigmoid(np.add(np.dot(p.W_i.v,z),p.b_i.v))\n",
        "    C_bar = tanh(np.add(np.dot(p.W_C.v,z),p.b_C.v))\n",
        "\n",
        "    C = np.add(f*C_prev,i*C_bar)\n",
        "    o = sigmoid(np.add(np.dot(p.W_o.v,z), p.b_o.v))\n",
        "    h = o*tanh(C)\n",
        "\n",
        "    v = np.add(np.dot(p.W_v.v,h),p.b_v.v)\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG",
        "colab_type": "text"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S",
        "colab_type": "text"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is Used to clear the Gradients\n",
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA",
        "colab_type": "text"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# It clips the values of the array is they exceeed the maximum or minimum constraints\n",
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y",
        "colab_type": "text"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV",
        "colab_type": "text"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L",
        "colab_type": "text"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a",
        "colab_type": "text"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK",
        "colab_type": "text"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS",
        "colab_type": "text"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab_type": "code",
        "outputId": "4e495d7f-8286-4a89-a55a-2b8baf1e651b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        }
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXEAAAD1CAYAAACm0cXeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " patient is thes Dipeany to get lisp of coronavirus or wase wese health care sor can aclucen all Disease. \n",
            "\n",
            "But in China, and MER0, there virl people.\n",
            "\n",
            "Iviting. Woshin, Inditha for did thing ou beet do \n",
            "----\n",
            "iter 49900, loss 6.180484\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFmwGN0A-VWD",
        "colab_type": "code",
        "outputId": "a117d8e5-a2ab-4571-aeef-2a3261ac8903",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "iter = 50000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 100 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAD1CAYAAACiJBXjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wEnH9gSFMqB/QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " effoctiev in eacely is inges we lime are symi(Saninoged through dever ge mare plane causes, or five aiferning to the Europeaningop other your haspital Medical in ithes 6,00 chesen spat rcnes.\n",
            "\n",
            "Some ty \n",
            "----\n",
            "iter 99900, loss 3.316695\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-",
        "colab_type": "text"
      },
      "source": [
        "# Quiz Questions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhfbLqD7Hida",
        "colab_type": "text"
      },
      "source": [
        "## Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IdzutbFv-Jw",
        "colab_type": "code",
        "outputId": "577a954d-1f98-4a54-e27d-5124f3cceb45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(sigmoid(0))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdKOoTipHrUB",
        "colab_type": "text"
      },
      "source": [
        "## Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qU-zo6MaH4zn",
        "colab_type": "code",
        "outputId": "c765341c-f006-4d8e-816d-38eb01961f62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeFNdWAAHtby",
        "colab_type": "text"
      },
      "source": [
        "## Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE1b4YnkH50O",
        "colab_type": "code",
        "outputId": "a1a550f1-6330-498f-b910-1f1e09e60b46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tanh(dsigmoid(sigmoid(0))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.24491866240370908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TEJTV7tHvhT",
        "colab_type": "text"
      },
      "source": [
        "## Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjJ3IjqOHfSZ",
        "colab_type": "code",
        "outputId": "155d8e9e-d9bc-4abb-fe75-28fe956ccb9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(dtanh(tanh(dsigmoid(sigmoid(0)))))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.940014848806378\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mXkl7M-ILlX",
        "colab_type": "text"
      },
      "source": [
        "## Quiz Question 5\n",
        "\n",
        "In the class definition of Parameter class, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6WCPK00IOzc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size_a = Hidden_Layer_size #Number of Layers in one DNN\n",
        "size_b = z_size # Dimensionality of Hidden Layer\n",
        "size_c = X_size # Total Number of Character\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOpfkBq9ItFa",
        "colab_type": "text"
      },
      "source": [
        "## Quiz Question 6\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ia6AcGHVItyO",
        "colab_type": "code",
        "outputId": "7082f65a-cb4c-4913-b0cb-ebc9a8dec329",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVpRSf2GI-1i",
        "colab_type": "text"
      },
      "source": [
        "## Quiz Question 7 \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOAzFvgVJBE0",
        "colab_type": "code",
        "outputId": "a6714629-94b7-4cab-8392-47227f8c054f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(z.shape)\n",
        "print(np.sum(z))\n",
        "print(np.sum(f))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(175, 1)\n",
            "0.0\n",
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RgmPjejDJUE8",
        "colab_type": "text"
      },
      "source": [
        "## Quiz Question 8\n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiMz4bgcJYFg",
        "colab_type": "text"
      },
      "source": [
        "## Quiz Question 9\n",
        "\n",
        "Run the above code for further 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9Mma5ck1o4w",
        "colab_type": "text"
      },
      "source": [
        "Answer: 3.31\n"
      ]
    }
  ]
}